{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import range, input\n",
    "from datetime import datetime\n",
    "from future.utils import iteritems\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the implementation of the NaiveBayes class, which contains three methods within it. The first, fit, takes the model, the features and labels lists, and a smoothing constant. It creates two dictionaries, one called gaussians which stores the mean and variance using the built in numpy methods .mean() https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html and .var() https://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.var.html and one called priors. c is the current class [0 ... 9], and gaussians holds the mean and variance for each current_x in the class. This is the training method we are going to be using. \n",
    "\n",
    "The score method takes in the list of features and labels again, as well as the model. It starts by getting a list of the model's predictions based on the features, then runs through all the classes and counts true positives, false positives, and total instances of the class.\n",
    "\n",
    "The predict function utilizes a numpy method called shape https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html, which is used to get the shape of the array. Following, it creates an array P using the numpy method zeros to create an array with the same shape of size N, K. it then iterates through the gaussians dictionary to use the scipy.stats logpdf function to get the probability that the current item is in a given class c. At the end, it takes the one with the highest probability and returns the array filled with that.\n",
    "\n",
    "The fit function and predict function were taken from https://github.com/lazyprogrammer/machine_learning_examples/blob/master/supervised_class/nb.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    def fit(self, X, Y, smoothing=1e-2):\n",
    "        self.gaussians = dict()\n",
    "        self.priors = dict()\n",
    "        labels = set(Y)\n",
    "        for c in labels:\n",
    "            current_x = X[Y == c]\n",
    "            self.gaussians[c] = {\n",
    "                'mean': current_x.mean(axis=0),\n",
    "                'var': current_x.var(axis=0) + smoothing,\n",
    "            }\n",
    "            self.priors[c] = float(len(Y[Y == c])) / len(Y)\n",
    "\n",
    "    def score(self, features, labels):\n",
    "        P = self.predict(features)\n",
    "        for j in range(10):\n",
    "            true_positives = 0\n",
    "            predicted_amount = 0\n",
    "            for i in range(len(P)):\n",
    "                if P[i] == j:\n",
    "                    predicted_amount +=1\n",
    "                    if labels[i] == P[i]:\n",
    "                        true_positives += 1\n",
    "            tags = 0\n",
    "            tag_amount = len([i for i in labels if i == j])\n",
    "            for i in range(len(labels)):\n",
    "                if labels[i] == P[i] == j:\n",
    "                    tags += 1\n",
    "            print(j,\"- Recall:\", round(tags/tag_amount, 2), \"Precision:\", round(true_positives/predicted_amount, 2))\n",
    "        return np.mean(P == labels)\n",
    "\n",
    "    def predict(self, features):\n",
    "        N, D = features.shape\n",
    "        K = len(self.gaussians)\n",
    "        P = np.zeros((N, K))\n",
    "        for c, g in iteritems(self.gaussians):\n",
    "            mean, var = g['mean'], g['var']\n",
    "            P[:,c] = mvn.logpdf(features, mean=mean, cov=var) + np.log(self.priors[c])\n",
    "        return np.argmax(P, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_data method takes in the file, and shuffles the data to randomize the dataset for each run. We then take the data and divide each entry into a float value from 0.0 to 1.0, which represents the previous 0 to 255 integer value. the data is splitt into featurs and labels, with X representing the features and Y representing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(limit):\n",
    "    print(\"Reading in and transforming data...\")\n",
    "    df = pd.read_csv(\"train.csv\", encoding=\"ISO-8859-1\")\n",
    "    data = df.values\n",
    "    np.random.shuffle(data)\n",
    "    features = data[:, 1:] / 255.0 \n",
    "    labels = data[:, 0]\n",
    "    features, labels = features[:limit], labels[:limit]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get our features and our labels using the above get_data method, with a limit of the entire dataset. We create a variable Ntrain to get the datasplit we are going to be working with. We then seperate the data into a training set and a test set for us to utilize later. We create a Naive Bayes object,  then train it using the model.fit method.  we then use the model.score method on both our training set and our test set to get our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n",
      "Training time: 0:00:01.130846\n",
      "0 - Recall: 0.9 Precision: 0.93\n",
      "1 - Recall: 0.96 Precision: 0.79\n",
      "2 - Recall: 0.75 Precision: 0.9\n",
      "3 - Recall: 0.75 Precision: 0.81\n",
      "4 - Recall: 0.65 Precision: 0.84\n",
      "5 - Recall: 0.61 Precision: 0.88\n",
      "6 - Recall: 0.93 Precision: 0.83\n",
      "7 - Recall: 0.8 Precision: 0.94\n",
      "8 - Recall: 0.75 Precision: 0.64\n",
      "9 - Recall: 0.87 Precision: 0.6\n",
      "Train accuracy: 79.84 %\n",
      "Train size: 29400\n",
      "\n",
      "0 - Recall: 0.9 Precision: 0.94\n",
      "1 - Recall: 0.97 Precision: 0.78\n",
      "2 - Recall: 0.74 Precision: 0.91\n",
      "3 - Recall: 0.76 Precision: 0.8\n",
      "4 - Recall: 0.64 Precision: 0.83\n",
      "5 - Recall: 0.61 Precision: 0.86\n",
      "6 - Recall: 0.91 Precision: 0.85\n",
      "7 - Recall: 0.81 Precision: 0.95\n",
      "8 - Recall: 0.72 Precision: 0.63\n",
      "9 - Recall: 0.87 Precision: 0.63\n",
      "Test accuracy: 80.12 %\n",
      "Test size: 12600\n"
     ]
    }
   ],
   "source": [
    "features, labels = get_data(42000)\n",
    "Ntrain = len(labels) // 10 * 3\n",
    "featuresTrain, labelsTrain = features[Ntrain:], labels[Ntrain:]\n",
    "featuresTest, labelsTest = features[:Ntrain], labels[:Ntrain]\n",
    "\n",
    "model = NaiveBayes()\n",
    "model.fit(featuresTrain, labelsTrain)\n",
    "\n",
    "print(\"Train accuracy:\", round(model.score(featuresTrain, labelsTrain)*100, 2),\"%\")\n",
    "print(\"Train size:\", len(labelsTrain))\n",
    "\n",
    "print()\n",
    "print(\"Test accuracy:\", round(model.score(featuresTest, labelsTest)*100, 2),\"%\")\n",
    "print(\"Test size:\", len(labelsTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the data above, we get around 80% accuracy for both the training set and the test set. This is about what I was expecting, as the downfall of using Naive Bayes is that there isn't a way to tie together features to gain a different perspective. Many of the features are present in multiple numbers, which leads to a greater level of misclassification. If you look at our recall and accuracy, you notice that there is a dip in recall for 4s and 5s, and a dip in precision for 8's and 9's. This is due to the 9's being classified as 4's, and the 8's being classified as 5's."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
